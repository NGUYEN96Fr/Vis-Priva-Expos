Loading config /home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Custom Parameters: 
{'dataset': {'train': {'name': 'custom_30cls', 'img_path': '/home/users/vnguyen/intern20/DATA/250_imgs_per_class_cluster_IMT/train', 'ann_path': '/home/users/vnguyen/intern20/ANNO/coco_formatted_dataset_imt.json'}, 'test': {'name': None, 'img_path': None, 'ann_path': None}}, 'data_loader': {'num_workers': 4}, 'output_dir': {'path': '/home/users/vnguyen/intern20/ANNO/OUTPUTS/detec2'}, 'model': {'name': 'retinanet_R_50_FPN_1x', 'weight': '/home/users/vnguyen/intern20/Pretrained-Weight/dtec2/model_final_f10217.pkl', 'roi_heads': {'batch_size_per_image': 128, 'num_classes': 28}}, 'solver': {'ims_per_batch': 4, 'base_lr': 0.00025, 'max_iter': 1000}}
Configuration: 
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: (None,)
  TRAIN: ('custom_30cls',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 40.31747359663594, 50.79683366298238], [64, 80.63494719327188, 101.59366732596476], [128, 161.26989438654377, 203.18733465192952], [256, 322.53978877308754, 406.37466930385904], [512, 645.0795775461751, 812.7493386077181]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: RetinaNet
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.0
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 28
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: /home/users/vnguyen/intern20/Pretrained-Weight/dtec2/model_final_f10217.pkl
OUTPUT_DIR: /home/users/vnguyen/intern20/ANNO/OUTPUTS/detec2
SEED: -1
SOLVER:
  BASE_LR: 0.00025
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 1000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (60000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[32m[07/15 17:44:30 d2.engine.defaults]: [0mModel:
RetinaNet(
  (backbone): FPN(
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (head): RetinaNetHead(
    (cls_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (bbox_subnet): Sequential(
      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (cls_score): Conv2d(256, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (anchor_generator): DefaultAnchorGenerator(
    (cell_anchors): BufferList()
  )
)
[32m[07/15 17:44:30 d2.data.datasets.coco]: [0mLoaded 3701 images in COCO format from /home/users/vnguyen/intern20/ANNO/coco_formatted_dataset_imt.json
[32m[07/15 17:44:30 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3701 images left.
[32m[07/15 17:44:30 d2.data.build]: [0mDistribution of instances among all 28 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|   person   | 252          |  bicycle   | 250          |    car     | 253          |
|  airplane  | 252          |    bus     | 250          |    boat    | 256          |
|   train    | 250          |   truck    | 250          |   bench    | 250          |
|    bird    | 256          |    cat     | 250          |    dog     | 250          |
|   horse    | 250          |   sheep    | 253          |   toilet   | 250          |
|    bed     | 250          |    tie     | 255          |  suitcase  | 250          |
|    kite    | 251          |    cup     | 251          |    fork    | 250          |
|   banana   | 251          |   pizza    | 250          |   couch    | 250          |
|   laptop   | 250          |   remote   | 251          |    book    | 254          |
| microwave  | 253          |            |              |            |              |
|   total    | 7038         |            |              |            |              |[0m
[32m[07/15 17:44:30 d2.data.common]: [0mSerializing 3701 elements to byte tensors and concatenating them all ...
[32m[07/15 17:44:30 d2.data.common]: [0mSerialized dataset takes 1.10 MiB
[32m[07/15 17:44:30 d2.data.dataset_mapper]: [0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[07/15 17:44:30 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[07/15 17:44:32 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[07/15 17:44:44 d2.utils.events]: [0m eta: 0:09:00  iter: 19  total_loss: 2.012  loss_cls: 1.375  loss_box_reg: 0.637  time: 0.5518  data_time: 0.0445  lr: 0.000005  max_mem: 7382M
[32m[07/15 17:44:56 d2.utils.events]: [0m eta: 0:08:48  iter: 39  total_loss: 1.413  loss_cls: 0.978  loss_box_reg: 0.437  time: 0.5530  data_time: 0.0064  lr: 0.000010  max_mem: 7382M
[32m[07/15 17:45:07 d2.utils.events]: [0m eta: 0:08:48  iter: 59  total_loss: 1.866  loss_cls: 1.240  loss_box_reg: 0.639  time: 0.5573  data_time: 0.0064  lr: 0.000015  max_mem: 7383M
[32m[07/15 17:45:18 d2.utils.events]: [0m eta: 0:08:36  iter: 79  total_loss: 1.709  loss_cls: 1.167  loss_box_reg: 0.544  time: 0.5576  data_time: 0.0065  lr: 0.000020  max_mem: 7383M
[32m[07/15 17:45:29 d2.utils.events]: [0m eta: 0:08:21  iter: 99  total_loss: 2.046  loss_cls: 1.377  loss_box_reg: 0.669  time: 0.5549  data_time: 0.0062  lr: 0.000025  max_mem: 7383M
[32m[07/15 17:45:40 d2.utils.events]: [0m eta: 0:08:07  iter: 119  total_loss: 1.933  loss_cls: 1.287  loss_box_reg: 0.645  time: 0.5524  data_time: 0.0063  lr: 0.000030  max_mem: 7383M
[32m[07/15 17:45:50 d2.utils.events]: [0m eta: 0:07:54  iter: 139  total_loss: 1.572  loss_cls: 1.055  loss_box_reg: 0.518  time: 0.5489  data_time: 0.0058  lr: 0.000035  max_mem: 7383M
[32m[07/15 17:46:01 d2.utils.events]: [0m eta: 0:07:43  iter: 159  total_loss: 1.977  loss_cls: 1.324  loss_box_reg: 0.682  time: 0.5499  data_time: 0.0064  lr: 0.000040  max_mem: 7383M
[32m[07/15 17:46:12 d2.utils.events]: [0m eta: 0:07:31  iter: 179  total_loss: 1.658  loss_cls: 1.086  loss_box_reg: 0.542  time: 0.5492  data_time: 0.0060  lr: 0.000045  max_mem: 7383M
[32m[07/15 17:46:23 d2.utils.events]: [0m eta: 0:07:20  iter: 199  total_loss: 1.748  loss_cls: 1.097  loss_box_reg: 0.585  time: 0.5490  data_time: 0.0061  lr: 0.000050  max_mem: 7383M
[32m[07/15 17:46:34 d2.utils.events]: [0m eta: 0:07:09  iter: 219  total_loss: 1.624  loss_cls: 1.118  loss_box_reg: 0.507  time: 0.5484  data_time: 0.0060  lr: 0.000055  max_mem: 7383M
[32m[07/15 17:46:45 d2.utils.events]: [0m eta: 0:06:58  iter: 239  total_loss: 1.612  loss_cls: 1.102  loss_box_reg: 0.511  time: 0.5483  data_time: 0.0060  lr: 0.000060  max_mem: 7383M
[32m[07/15 17:46:56 d2.utils.events]: [0m eta: 0:06:46  iter: 259  total_loss: 1.685  loss_cls: 1.135  loss_box_reg: 0.550  time: 0.5474  data_time: 0.0058  lr: 0.000065  max_mem: 7383M
[32m[07/15 17:47:07 d2.utils.events]: [0m eta: 0:06:35  iter: 279  total_loss: 1.837  loss_cls: 1.249  loss_box_reg: 0.584  time: 0.5475  data_time: 0.0064  lr: 0.000070  max_mem: 7383M
[32m[07/15 17:47:18 d2.utils.events]: [0m eta: 0:06:25  iter: 299  total_loss: 1.575  loss_cls: 1.064  loss_box_reg: 0.575  time: 0.5489  data_time: 0.0064  lr: 0.000075  max_mem: 7383M
[32m[07/15 17:47:29 d2.utils.events]: [0m eta: 0:06:15  iter: 319  total_loss: 1.651  loss_cls: 1.118  loss_box_reg: 0.517  time: 0.5492  data_time: 0.0061  lr: 0.000080  max_mem: 7383M
[32m[07/15 17:47:41 d2.utils.events]: [0m eta: 0:06:06  iter: 339  total_loss: 1.920  loss_cls: 1.330  loss_box_reg: 0.604  time: 0.5502  data_time: 0.0067  lr: 0.000085  max_mem: 7383M
[32m[07/15 17:47:52 d2.utils.events]: [0m eta: 0:05:54  iter: 359  total_loss: 1.759  loss_cls: 1.202  loss_box_reg: 0.564  time: 0.5506  data_time: 0.0061  lr: 0.000090  max_mem: 7383M
[32m[07/15 17:48:03 d2.utils.events]: [0m eta: 0:05:42  iter: 379  total_loss: 1.871  loss_cls: 1.265  loss_box_reg: 0.606  time: 0.5508  data_time: 0.0058  lr: 0.000095  max_mem: 7383M
[32m[07/15 17:48:14 d2.utils.events]: [0m eta: 0:05:31  iter: 399  total_loss: 1.690  loss_cls: 1.139  loss_box_reg: 0.551  time: 0.5504  data_time: 0.0062  lr: 0.000100  max_mem: 7383M
[32m[07/15 17:48:25 d2.utils.events]: [0m eta: 0:05:20  iter: 419  total_loss: 1.710  loss_cls: 1.176  loss_box_reg: 0.541  time: 0.5505  data_time: 0.0063  lr: 0.000105  max_mem: 7383M
[32m[07/15 17:48:36 d2.utils.events]: [0m eta: 0:05:09  iter: 439  total_loss: 1.860  loss_cls: 1.257  loss_box_reg: 0.637  time: 0.5506  data_time: 0.0062  lr: 0.000110  max_mem: 7383M
[32m[07/15 17:48:47 d2.utils.events]: [0m eta: 0:04:58  iter: 459  total_loss: 1.763  loss_cls: 1.202  loss_box_reg: 0.561  time: 0.5501  data_time: 0.0063  lr: 0.000115  max_mem: 7383M
[32m[07/15 17:48:58 d2.utils.events]: [0m eta: 0:04:47  iter: 479  total_loss: 1.649  loss_cls: 1.101  loss_box_reg: 0.581  time: 0.5499  data_time: 0.0061  lr: 0.000120  max_mem: 7383M
[32m[07/15 17:49:09 d2.utils.events]: [0m eta: 0:04:36  iter: 499  total_loss: 1.719  loss_cls: 1.160  loss_box_reg: 0.557  time: 0.5498  data_time: 0.0064  lr: 0.000125  max_mem: 7383M
[32m[07/15 17:49:19 d2.utils.events]: [0m eta: 0:04:24  iter: 519  total_loss: 1.812  loss_cls: 1.206  loss_box_reg: 0.595  time: 0.5495  data_time: 0.0062  lr: 0.000130  max_mem: 7383M
[32m[07/15 17:49:30 d2.utils.events]: [0m eta: 0:04:13  iter: 539  total_loss: 1.810  loss_cls: 1.243  loss_box_reg: 0.582  time: 0.5485  data_time: 0.0058  lr: 0.000135  max_mem: 7383M
[32m[07/15 17:49:41 d2.utils.events]: [0m eta: 0:04:02  iter: 559  total_loss: 1.253  loss_cls: 0.876  loss_box_reg: 0.384  time: 0.5484  data_time: 0.0066  lr: 0.000140  max_mem: 7383M
[32m[07/15 17:49:52 d2.utils.events]: [0m eta: 0:03:51  iter: 579  total_loss: 2.029  loss_cls: 1.260  loss_box_reg: 0.720  time: 0.5481  data_time: 0.0061  lr: 0.000145  max_mem: 7383M
[32m[07/15 17:50:02 d2.utils.events]: [0m eta: 0:03:40  iter: 599  total_loss: 1.574  loss_cls: 1.051  loss_box_reg: 0.530  time: 0.5478  data_time: 0.0059  lr: 0.000150  max_mem: 7383M
[32m[07/15 17:50:14 d2.utils.events]: [0m eta: 0:03:29  iter: 619  total_loss: 2.040  loss_cls: 1.349  loss_box_reg: 0.644  time: 0.5485  data_time: 0.0063  lr: 0.000155  max_mem: 7383M
[32m[07/15 17:50:25 d2.utils.events]: [0m eta: 0:03:18  iter: 639  total_loss: 1.816  loss_cls: 1.243  loss_box_reg: 0.565  time: 0.5484  data_time: 0.0064  lr: 0.000160  max_mem: 7383M
[32m[07/15 17:50:36 d2.utils.events]: [0m eta: 0:03:07  iter: 659  total_loss: 1.862  loss_cls: 1.236  loss_box_reg: 0.595  time: 0.5485  data_time: 0.0065  lr: 0.000165  max_mem: 7383M
[32m[07/15 17:50:46 d2.utils.events]: [0m eta: 0:02:56  iter: 679  total_loss: 1.735  loss_cls: 1.168  loss_box_reg: 0.548  time: 0.5481  data_time: 0.0063  lr: 0.000170  max_mem: 7383M
[32m[07/15 17:50:58 d2.utils.events]: [0m eta: 0:02:45  iter: 699  total_loss: 1.683  loss_cls: 1.112  loss_box_reg: 0.586  time: 0.5482  data_time: 0.0059  lr: 0.000175  max_mem: 7383M
[32m[07/15 17:51:08 d2.utils.events]: [0m eta: 0:02:34  iter: 719  total_loss: 1.697  loss_cls: 1.115  loss_box_reg: 0.545  time: 0.5481  data_time: 0.0068  lr: 0.000180  max_mem: 7383M
[32m[07/15 17:51:19 d2.utils.events]: [0m eta: 0:02:23  iter: 739  total_loss: 1.962  loss_cls: 1.245  loss_box_reg: 0.634  time: 0.5481  data_time: 0.0061  lr: 0.000185  max_mem: 7383M
[32m[07/15 17:51:31 d2.utils.events]: [0m eta: 0:02:12  iter: 759  total_loss: 1.555  loss_cls: 1.085  loss_box_reg: 0.462  time: 0.5489  data_time: 0.0060  lr: 0.000190  max_mem: 7383M
[32m[07/15 17:51:42 d2.utils.events]: [0m eta: 0:02:01  iter: 779  total_loss: 1.691  loss_cls: 1.161  loss_box_reg: 0.529  time: 0.5486  data_time: 0.0064  lr: 0.000195  max_mem: 7383M
[32m[07/15 17:51:53 d2.utils.events]: [0m eta: 0:01:50  iter: 799  total_loss: 1.667  loss_cls: 1.168  loss_box_reg: 0.499  time: 0.5489  data_time: 0.0059  lr: 0.000200  max_mem: 7383M
[32m[07/15 17:52:04 d2.utils.events]: [0m eta: 0:01:39  iter: 819  total_loss: 1.924  loss_cls: 1.306  loss_box_reg: 0.603  time: 0.5491  data_time: 0.0066  lr: 0.000205  max_mem: 7383M
[32m[07/15 17:52:15 d2.utils.events]: [0m eta: 0:01:28  iter: 839  total_loss: 1.587  loss_cls: 1.077  loss_box_reg: 0.495  time: 0.5488  data_time: 0.0058  lr: 0.000210  max_mem: 7383M
[32m[07/15 17:52:26 d2.utils.events]: [0m eta: 0:01:17  iter: 859  total_loss: 2.097  loss_cls: 1.444  loss_box_reg: 0.661  time: 0.5486  data_time: 0.0060  lr: 0.000215  max_mem: 7383M
[32m[07/15 17:52:37 d2.utils.events]: [0m eta: 0:01:06  iter: 879  total_loss: 1.487  loss_cls: 1.045  loss_box_reg: 0.470  time: 0.5489  data_time: 0.0061  lr: 0.000220  max_mem: 7383M
[32m[07/15 17:52:48 d2.utils.events]: [0m eta: 0:00:55  iter: 899  total_loss: 1.708  loss_cls: 1.203  loss_box_reg: 0.517  time: 0.5490  data_time: 0.0065  lr: 0.000225  max_mem: 7383M
[32m[07/15 17:52:59 d2.utils.events]: [0m eta: 0:00:44  iter: 919  total_loss: 1.694  loss_cls: 1.167  loss_box_reg: 0.516  time: 0.5490  data_time: 0.0063  lr: 0.000230  max_mem: 7383M
[32m[07/15 17:53:10 d2.utils.events]: [0m eta: 0:00:33  iter: 939  total_loss: 1.890  loss_cls: 1.268  loss_box_reg: 0.596  time: 0.5488  data_time: 0.0067  lr: 0.000235  max_mem: 7383M
[32m[07/15 17:53:21 d2.utils.events]: [0m eta: 0:00:22  iter: 959  total_loss: 1.451  loss_cls: 1.004  loss_box_reg: 0.447  time: 0.5487  data_time: 0.0064  lr: 0.000240  max_mem: 7383M
[32m[07/15 17:53:31 d2.utils.events]: [0m eta: 0:00:11  iter: 979  total_loss: 1.706  loss_cls: 1.196  loss_box_reg: 0.507  time: 0.5485  data_time: 0.0066  lr: 0.000245  max_mem: 7383M
[4m[5m[31mERROR[0m [32m[07/15 17:53:43 d2.engine.train_loop]: [0mException during training:
Traceback (most recent call last):
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/data/catalog.py", line 56, in get
    f = DatasetCatalog._REGISTERED[name]
KeyError: None

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/engine/train_loop.py", line 131, in train
    self.after_step()
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/engine/train_loop.py", line 152, in after_step
    h.after_step()
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/engine/hooks.py", line 349, in after_step
    self._do_eval()
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/engine/hooks.py", line 323, in _do_eval
    results = self._func()
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/engine/defaults.py", line 351, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/engine/defaults.py", line 500, in test
    data_loader = cls.build_test_loader(cfg, dataset_name)
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/engine/defaults.py", line 459, in build_test_loader
    return build_detection_test_loader(cfg, dataset_name)
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/data/build.py", line 373, in build_detection_test_loader
    dataset_dicts = get_detection_dataset_dicts(
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/data/build.py", line 219, in get_detection_dataset_dicts
    dataset_dicts = [DatasetCatalog.get(dataset_name) for dataset_name in dataset_names]
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/data/build.py", line 219, in <listcomp>
    dataset_dicts = [DatasetCatalog.get(dataset_name) for dataset_name in dataset_names]
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/data/catalog.py", line 58, in get
    raise KeyError(
KeyError: "Dataset 'None' is not registered! Available datasets are: coco_2014_train, coco_2014_val, coco_2014_minival, coco_2014_minival_100, coco_2014_valminusminival, coco_2017_train, coco_2017_val, coco_2017_test, coco_2017_test-dev, coco_2017_val_100, keypoints_coco_2014_train, keypoints_coco_2014_val, keypoints_coco_2014_minival, keypoints_coco_2014_valminusminival, keypoints_coco_2014_minival_100, keypoints_coco_2017_train, keypoints_coco_2017_val, keypoints_coco_2017_val_100, coco_2017_train_panoptic_separated, coco_2017_train_panoptic_stuffonly, coco_2017_val_panoptic_separated, coco_2017_val_panoptic_stuffonly, coco_2017_val_100_panoptic_separated, coco_2017_val_100_panoptic_stuffonly, lvis_v1_train, lvis_v1_val, lvis_v1_test_dev, lvis_v1_test_challenge, lvis_v0.5_train, lvis_v0.5_val, lvis_v0.5_val_rand_100, lvis_v0.5_test, lvis_v0.5_train_cocofied, lvis_v0.5_val_cocofied, cityscapes_fine_instance_seg_train, cityscapes_fine_sem_seg_train, cityscapes_fine_instance_seg_val, cityscapes_fine_sem_seg_val, cityscapes_fine_instance_seg_test, cityscapes_fine_sem_seg_test, voc_2007_trainval, voc_2007_train, voc_2007_val, voc_2007_test, voc_2012_trainval, voc_2012_train, voc_2012_val, custom_30cls"
[32m[07/15 17:53:43 d2.engine.hooks]: [0mOverall training speed: 997 iterations in 0:09:07 (0.5490 s / it)
[32m[07/15 17:53:43 d2.engine.hooks]: [0mTotal training time: 0:09:08 (0:00:01 on hooks)
Traceback (most recent call last):
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/data/catalog.py", line 56, in get
    f = DatasetCatalog._REGISTERED[name]
KeyError: None

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "custom_train.py", line 55, in <module>
    main()
  File "custom_train.py", line 52, in main
    trainer.train()
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/engine/defaults.py", line 398, in train
    super().train(self.start_iter, self.max_iter)
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/engine/train_loop.py", line 131, in train
    self.after_step()
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/engine/train_loop.py", line 152, in after_step
    h.after_step()
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/engine/hooks.py", line 349, in after_step
    self._do_eval()
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/engine/hooks.py", line 323, in _do_eval
    results = self._func()
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/engine/defaults.py", line 351, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/engine/defaults.py", line 500, in test
    data_loader = cls.build_test_loader(cfg, dataset_name)
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/engine/defaults.py", line 459, in build_test_loader
    return build_detection_test_loader(cfg, dataset_name)
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/data/build.py", line 373, in build_detection_test_loader
    dataset_dicts = get_detection_dataset_dicts(
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/data/build.py", line 219, in get_detection_dataset_dicts
    dataset_dicts = [DatasetCatalog.get(dataset_name) for dataset_name in dataset_names]
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/data/build.py", line 219, in <listcomp>
    dataset_dicts = [DatasetCatalog.get(dataset_name) for dataset_name in dataset_names]
  File "/home/users/vnguyen/intern20/Vis-Priva-Expos/training_scripts/detectron2/detectron2/data/catalog.py", line 58, in get
    raise KeyError(
KeyError: "Dataset 'None' is not registered! Available datasets are: coco_2014_train, coco_2014_val, coco_2014_minival, coco_2014_minival_100, coco_2014_valminusminival, coco_2017_train, coco_2017_val, coco_2017_test, coco_2017_test-dev, coco_2017_val_100, keypoints_coco_2014_train, keypoints_coco_2014_val, keypoints_coco_2014_minival, keypoints_coco_2014_valminusminival, keypoints_coco_2014_minival_100, keypoints_coco_2017_train, keypoints_coco_2017_val, keypoints_coco_2017_val_100, coco_2017_train_panoptic_separated, coco_2017_train_panoptic_stuffonly, coco_2017_val_panoptic_separated, coco_2017_val_panoptic_stuffonly, coco_2017_val_100_panoptic_separated, coco_2017_val_100_panoptic_stuffonly, lvis_v1_train, lvis_v1_val, lvis_v1_test_dev, lvis_v1_test_challenge, lvis_v0.5_train, lvis_v0.5_val, lvis_v0.5_val_rand_100, lvis_v0.5_test, lvis_v0.5_train_cocofied, lvis_v0.5_val_cocofied, cityscapes_fine_instance_seg_train, cityscapes_fine_sem_seg_train, cityscapes_fine_instance_seg_val, cityscapes_fine_sem_seg_val, cityscapes_fine_instance_seg_test, cityscapes_fine_sem_seg_test, voc_2007_trainval, voc_2007_train, voc_2007_val, voc_2007_test, voc_2012_trainval, voc_2012_train, voc_2012_val, custom_30cls"
